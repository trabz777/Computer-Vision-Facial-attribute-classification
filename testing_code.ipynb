{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"testing_code.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1rlnag--wiKtbdUfoxkjI8UbM6AUj-VFj","authorship_tag":"ABX9TyPLno+3Rq2o9p0M47JDyqjD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LCVXfnyxfREJ"},"source":["Importing all required libraries:"]},{"cell_type":"code","metadata":{"id":"d7Zr1tdhRDoq"},"source":["from google.colab import drive\n","\n","import numpy as np\n","import pandas as pd\n","\n","import cv2\n","from os import listdir\n","\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models, optimizers\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from keras.models import Model, load_model\n","from tensorflow import keras\n","from tensorflow.keras.layers.experimental import preprocessing\n","from keras.applications.vgg16 import VGG16\n","from keras.callbacks import ModelCheckpoint\n","from keras.applications import ResNet101, ResNet152,  ResNet50V2, ResNet101V2, ResNet152V2, DenseNet121, DenseNet169, DenseNet201, NASNetLarge, ResNet50\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2MnHtq9zZjNz"},"source":["Mounting Google Drive:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msCYOrt0Zmmc","executionInfo":{"status":"ok","timestamp":1618551919981,"user_tz":-60,"elapsed":794,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"083d20c1-f12a-421d-a9ef-1f6702f8fdee"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NaClN8Vjbts2"},"source":["Annotating the new images manually, not using the annotation tool as 10 images can be annotated easily like this. \n","Importing the new images and adding them to main dataframe (df):"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"QykBC-iFbpQ5","executionInfo":{"status":"ok","timestamp":1618551964353,"user_tz":-60,"elapsed":41406,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"068cad97-f3e0-4d64-a131-a2c9218db49f"},"source":["# Annotating the new images manually\n","data = {'file_name': ['image1.jpg','image2.jpg','image3.jpg','image4.jpg','image5.jpg','image6.jpg','image7.jpg','image8.jpg','image9.jpg','image10.jpg'],\n","        'wrinkles': [0,1,1,0,0,0,0,0,1,0],\n","        'freakles': [1,1,0,0,0,0,0,1,1,0],\n","        'glasses': [0,0,0,0,1,0,0,0,2,0],\n","        'hair color': [0,8,1,0,1,5,3,1,1,6],\n","        'hair top': [2,3,1,1,2,2,2,3,2,1]\n","        }\n","\n","df = pd.DataFrame(data, columns= ['file_name', 'wrinkles','freakles','glasses','hair color','hair top'])\n","\n","\n","# importing all the new images from Drive using open-cv2 and adding them to our dataframe\n","dir_struct = '/content/drive/MyDrive/new images/'\n","image_list = [] # this list will hold all the images\n","#for i in range(1):\n","for i in range(df.shape[0]): # read the image one by one\n","    image = cv2.imread(dir_struct+df.iloc[i]['file_name'])\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BGR to RGB convert\n","    image = cv2.resize(image, (96,96), interpolation = cv2.INTER_AREA) # resizing all images to 32x32: NOT ideal but need to be uniform in order to apply the algorithm\n","                                                                                                                        # this actually ensures all the features [pixel values] will be of same size\n","    image_list.append(image) # appending the read image to a list\n","\n","df['images'] = image_list\n","\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>wrinkles</th>\n","      <th>freakles</th>\n","      <th>glasses</th>\n","      <th>hair color</th>\n","      <th>hair top</th>\n","      <th>images</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>image1.jpg</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>[[[96, 80, 70], [102, 85, 77], [58, 46, 44], [...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>image2.jpg</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>[[[245, 248, 253], [245, 248, 253], [245, 248,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>image3.jpg</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[[[49, 47, 44], [43, 39, 36], [37, 33, 29], [3...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>image4.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>[[[118, 114, 122], [117, 113, 121], [118, 113,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>image5.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>[[[71, 62, 57], [72, 63, 58], [73, 64, 59], [7...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>image6.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>[[[207, 213, 230], [208, 214, 231], [209, 215,...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>image7.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>[[[59, 50, 52], [58, 50, 53], [59, 52, 55], [6...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>image8.jpg</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>[[[79, 45, 42], [84, 46, 43], [89, 48, 44], [9...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>image9.jpg</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>[[[245, 248, 253], [245, 248, 253], [245, 248,...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>image10.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>[[[147, 95, 84], [149, 96, 84], [150, 96, 84],...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     file_name  ...                                             images\n","0   image1.jpg  ...  [[[96, 80, 70], [102, 85, 77], [58, 46, 44], [...\n","1   image2.jpg  ...  [[[245, 248, 253], [245, 248, 253], [245, 248,...\n","2   image3.jpg  ...  [[[49, 47, 44], [43, 39, 36], [37, 33, 29], [3...\n","3   image4.jpg  ...  [[[118, 114, 122], [117, 113, 121], [118, 113,...\n","4   image5.jpg  ...  [[[71, 62, 57], [72, 63, 58], [73, 64, 59], [7...\n","5   image6.jpg  ...  [[[207, 213, 230], [208, 214, 231], [209, 215,...\n","6   image7.jpg  ...  [[[59, 50, 52], [58, 50, 53], [59, 52, 55], [6...\n","7   image8.jpg  ...  [[[79, 45, 42], [84, 46, 43], [89, 48, 44], [9...\n","8   image9.jpg  ...  [[[245, 248, 253], [245, 248, 253], [245, 248,...\n","9  image10.jpg  ...  [[[147, 95, 84], [149, 96, 84], [150, 96, 84],...\n","\n","[10 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"WVYqTeHxUDRQ"},"source":["Preprocessing:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzTaPa22UF1U","executionInfo":{"status":"ok","timestamp":1618551975514,"user_tz":-60,"elapsed":930,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"92320b8b-e50b-4200-d47f-8278eb3d5742"},"source":["# manually converting it to the shape which will be acceptable to the model\n","test_images = df[['images']]\n","test_images['images'] = test_images['images'].apply(lambda x:x.reshape(1, 96,96,3)[0])\n","\n","test_images = np.reshape([x for x in test_images['images'].values], (10, 96,96,3))\n","\n","test_images = test_images.astype('float32')\n","\n","# Normalizing\n","test_images = test_images / 255.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9JoT181OfX4p"},"source":["Importing trained model and its weights from Drive and then displaying the Evaluation Metrics\n","1. Wrinkles Model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAgyntCSQIyb","executionInfo":{"status":"ok","timestamp":1618551990418,"user_tz":-60,"elapsed":10535,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"60094fdf-210c-4d90-8037-d4590ced81b1"},"source":["# here you need to specify the saved model from before\n","filepath = \"/content/drive/MyDrive/VGG16-wrinkles-10-0.6750.h5\"\n","\n","# load the model\n","model = load_model(filepath)\n","\n","\n","y_pred1_wrinkles = model.predict(test_images)\n","y_pred_wrinkles = np.argmax(y_pred1_wrinkles, axis=1) \n","\n","test_loss, test_acc = model.evaluate(test_images,  df[['freakles']], verbose=2)\n","\n","print('These are the scores for the wrinkles attribute------------------------------------------------->')\n","print('Precision score: ')\n","print(precision_score(df[['wrinkles']], y_pred_wrinkles , average=\"micro\"))\n","print('Recall score: ')\n","print(recall_score(df[['wrinkles']], y_pred_wrinkles , average=\"micro\"))\n","\n","print('F1 score (macro): ')\n","print(f1_score(df[['wrinkles']], y_pred_wrinkles , average=\"macro\"))\n","print('F1 score (micro): ')\n","print(f1_score(df[['wrinkles']], y_pred_wrinkles , average=\"micro\"))\n","print('F1 score (weighted): ')\n","print(f1_score(df[['wrinkles']], y_pred_wrinkles , average=\"weighted\"))\n","\n","print('Test accuracy: ')\n","print(test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 - 1s - loss: 0.8409 - accuracy: 0.6000\n","These are the scores for the wrinkles attribute------------------------------------------------->\n","Precision score: \n","0.7\n","Recall score: \n","0.7\n","F1 score (macro): \n","0.4117647058823529\n","F1 score (micro): \n","0.7\n","F1 score (weighted): \n","0.5764705882352941\n","Test accuracy: \n","0.6000000238418579\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6bxfWUczpuhK"},"source":["2. Freakles Model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppedwRUSaNgs","executionInfo":{"status":"ok","timestamp":1618552070346,"user_tz":-60,"elapsed":10186,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"118c35bd-ccf3-4a4e-c61e-0816985c4537"},"source":["# here you need to specify the saved model from before\n","filepath = \"/content/drive/MyDrive/VGG16-freakles-10-0.7300.h5\"\n","\n","# load the model\n","model = load_model(filepath)\n","\n","\n","y_pred1_freakles = model.predict(test_images)\n","y_pred_freakles = np.argmax(y_pred1_freakles, axis=1) \n","\n","test_loss, test_acc = model.evaluate(test_images,  df[['freakles']], verbose=2)\n","\n","print('These are the scores for the freakles attribute------------------------------------------------->')\n","print('Precision score: ')\n","print(precision_score(df[['freakles']], y_pred_freakles , average=\"micro\"))\n","print('Recall score: ')\n","print(recall_score(df[['freakles']], y_pred_freakles , average=\"micro\"))\n","\n","print('F1 score (macro): ')\n","print(f1_score(df[['freakles']], y_pred_freakles , average=\"macro\"))\n","print('F1 score (micro): ')\n","print(f1_score(df[['freakles']], y_pred_freakles , average=\"micro\"))\n","print('F1 score (weighted): ')\n","print(f1_score(df[['freakles']], y_pred_freakles , average=\"weighted\"))\n","\n","print('Test accuracy: ')\n","print(test_acc)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 - 1s - loss: 0.7190 - accuracy: 0.6000\n","These are the scores for the freakles attribute------------------------------------------------->\n","Precision score: \n","0.6\n","Recall score: \n","0.6\n","F1 score (macro): \n","0.37499999999999994\n","F1 score (micro): \n","0.6\n","F1 score (weighted): \n","0.4499999999999999\n","Test accuracy: \n","0.6000000238418579\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uk7hwdXBqrup"},"source":["3. Glasses Model:"]},{"cell_type":"code","metadata":{"id":"A12Fv9MRv2ZQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618528986157,"user_tz":-60,"elapsed":5630,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"40536265-ab2e-4109-9119-554a78fcbf4a"},"source":["# here you need to specify the saved model from before\n","filepath = \"/content/drive/MyDrive/VGG16-glasses-10-0.8800.h5\"\n","\n","# load the model\n","model = load_model(filepath)\n","\n","\n","y_pred1_glasses = model.predict(test_images)\n","y_pred_glasses = np.argmax(y_pred1_glasses, axis=1) \n","\n","test_loss, test_acc = model.evaluate(test_images,  df[['glasses']], verbose=2)\n","\n","print('These are the scores for the glasses attribute------------------------------------------------->')\n","print('Precision score: ')\n","print(precision_score(df[['glasses']], y_pred_glasses , average=\"micro\"))\n","print('Recall score: ')\n","print(recall_score(df[['glasses']], y_pred_glasses , average=\"micro\"))\n","\n","print('F1 score (macro): ')\n","print(f1_score(df[['glasses']], y_pred_glasses , average=\"macro\"))\n","print('F1 score (micro): ')\n","print(f1_score(df[['glasses']], y_pred_glasses , average=\"micro\"))\n","print('F1 score (weighted): ')\n","print(f1_score(df[['glasses']], y_pred_glasses , average=\"weighted\"))\n","\n","print('Test accuracy: ')\n","print(test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fde8122aa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x7fde8111e8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 - 2s - loss: 0.6711 - accuracy: 0.8000\n","These are the scores for the glasses attribute------------------------------------------------->\n","Precision score: \n","0.8\n","Recall score: \n","0.8\n","F1 score (macro): \n","0.29629629629629634\n","F1 score (micro): \n","0.8000000000000002\n","F1 score (weighted): \n","0.7111111111111111\n","Test accuracy: \n","0.800000011920929\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pi75Dip_rpUr"},"source":["4. Hair color Model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmJzYAo7ruzW","executionInfo":{"status":"ok","timestamp":1618528995174,"user_tz":-60,"elapsed":12222,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"a1a9b5b9-20fa-4af1-8286-c619dbd3d90c"},"source":["# here you need to specify the saved model from before\n","filepath = \"/content/drive/MyDrive/VGG16-hair-color-10-0.3250.h5\"\n","\n","# load the model\n","model = load_model(filepath)\n","\n","\n","y_pred1_haircolor = model.predict(test_images)\n","y_pred_haircolor = np.argmax(y_pred1_haircolor, axis=1) \n","\n","test_loss, test_acc = model.evaluate(test_images,  df[['hair color']], verbose=2)\n","\n","print('These are the scores for the Hair Color attribute------------------------------------------------->')\n","print('Precision score: ')\n","print(precision_score(df[['hair color']], y_pred_haircolor , average=\"micro\"))\n","print('Recall score: ')\n","print(recall_score(df[['hair color']], y_pred_haircolor , average=\"micro\"))\n","\n","print('F1 score (macro): ')\n","print(f1_score(df[['hair color']], y_pred_haircolor , average=\"macro\"))\n","print('F1 score (micro): ')\n","print(f1_score(df[['hair color']], y_pred_haircolor , average=\"micro\"))\n","print('F1 score (weighted): ')\n","print(f1_score(df[['hair color']], y_pred_haircolor , average=\"weighted\"))\n","\n","print('Test accuracy: ')\n","print(test_acc)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fde928837a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fde8ed16950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 - 1s - loss: 1.6690 - accuracy: 0.4000\n","These are the scores for the Hair Color attribute------------------------------------------------->\n","Precision score: \n","0.4\n","Recall score: \n","0.4\n","F1 score (macro): \n","0.09523809523809525\n","F1 score (micro): \n","0.4000000000000001\n","F1 score (weighted): \n","0.2285714285714286\n","Test accuracy: \n","0.4000000059604645\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KC_xih6crvS4"},"source":["5. Hair top Model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlFJ4qO-rxl0","executionInfo":{"status":"ok","timestamp":1618530273129,"user_tz":-60,"elapsed":6569,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"3565e166-04de-4718-fcd2-9f2376849d89"},"source":["# here you need to specify the saved model from before\n","filepath = \"/content/drive/MyDrive/VGG16-hair-top-15-0.6450.h5\"\n","\n","# load the model\n","model = load_model(filepath)\n","\n","\n","y_pred1_hairtop = model.predict(test_images)\n","y_pred_hairtop = np.argmax(y_pred1_hairtop, axis=1) \n","\n","test_loss, test_acc = model.evaluate(test_images,  df[['hair top']], verbose=2)\n","\n","print('These are the scores for the Hair Top attribute------------------------------------------------->')\n","print('Precision score: ')\n","print(precision_score(df[['hair top']], y_pred_hairtop , average=\"micro\"))\n","print('Recall score: ')\n","print(recall_score(df[['hair top']], y_pred_hairtop , average=\"micro\"))\n","\n","print('F1 score (macro): ')\n","print(f1_score(df[['hair top']], y_pred_hairtop , average=\"macro\"))\n","print('F1 score (micro): ')\n","print(f1_score(df[['hair top']], y_pred_hairtop , average=\"micro\"))\n","print('F1 score (weighted): ')\n","print(f1_score(df[['hair top']], y_pred_hairtop , average=\"weighted\"))\n","\n","\n","print('Test accuracy: ')\n","print(test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fde8a22c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fde822959e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 - 1s - loss: 0.7072 - accuracy: 0.7000\n","These are the scores for the Hair Top attribute------------------------------------------------->\n","Precision score: \n","0.7\n","Recall score: \n","0.7\n","F1 score (macro): \n","0.6452991452991452\n","F1 score (micro): \n","0.7\n","F1 score (weighted): \n","0.667948717948718\n","Test accuracy: \n","0.699999988079071\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xtbWs7yL5YGY"},"source":["Exporting the predictions csv file as required and specified in the upload page for 'testing_code.ipynb':"]},{"cell_type":"code","metadata":{"id":"9PZv5bRwujo5","colab":{"base_uri":"https://localhost:8080/","height":714},"executionInfo":{"status":"ok","timestamp":1618530343673,"user_tz":-60,"elapsed":514,"user":{"displayName":"Abdullah Bin Zubair","photoUrl":"","userId":"12820815393513896022"}},"outputId":"a9743c3e-5be8-4b23-c68e-ea49e0336e5b"},"source":["df_predictions = df[['file_name']]\n","df_predictions['wrinkles'] = y_pred_wrinkles\n","df_predictions['freakles'] = y_pred_freakles\n","df_predictions['glasses'] = y_pred_glasses\n","df_predictions['hair color'] = y_pred_haircolor\n","df_predictions['hair top'] = y_pred_hairtop\n","\n","df_predictions.to_csv (r'/content/drive/MyDrive/predictions.csv', index = False, header=True)\n","\n","df_predictions.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>wrinkles</th>\n","      <th>freakles</th>\n","      <th>glasses</th>\n","      <th>hair color</th>\n","      <th>hair top</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>image1.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>image2.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>image3.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>image4.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>image5.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    file_name  wrinkles  freakles  glasses  hair color  hair top\n","0  image1.jpg         0         0        0           1         2\n","1  image2.jpg         0         0        0           1         3\n","2  image3.jpg         0         0        0           1         1\n","3  image4.jpg         0         0        0           1         2\n","4  image5.jpg         0         0        0           1         2"]},"metadata":{"tags":[]},"execution_count":22}]}]}